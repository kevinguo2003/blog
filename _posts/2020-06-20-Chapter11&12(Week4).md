---
layout: post
title: 'Chapter 11 and 12'
date: 2020-06-20
author: Xiao Guo
cover: '/assets/img/MountAl.jpg'
tags: CS3114 week4 data-structures
---

> Memory Management

### Definition and background
In this chapter, we will be focusing on the memory management techniques regarding handling space requests of variable size. Normally, we will have a big memory block called the memory pool. When we need a certain space to store our value, we will send a request to the memory manager which will then return some handles to clarify the memory we can use. Once when we don't need the space, we can deallocate the memory and leave it for future use. We will talk about this kind of dynamic memory allocation in the following section.

### Dynamic Storage Allocation
The key idea for dynamic storage is that when we need to store a data set of size k, then we need at least a memory block of size m where m is larger than k. This leads to two problems: The first one is what should we do when there is no block of size m that satisfies the requirement, which will require a proper garbage collection strategy. The second one is how to manage the memory block when there are too many small blocks caused by multiple operations.

### Sequential-Fit methods
There are two fundamental ways to deal with executing the freelist. The more straightforward methodology is to store the freelist independently from the memory pool. As it were, a basic connected rundown usage can be utilized, where every hub of the connected rundown contains a pointer to a solitary free square in the memory pool. This is fine if there is space accessible for the connected show itself, separate from the memory pool.
For detailed explanation [openDSA](https://canvas.vt.edu/courses/111334/modules/items/901507)

Approaches:from [openDSA](https://canvas.vt.edu/courses/111334/modules/items/901507)
1. First Fit: move down the free block list until a block that satisfies the requirement is found. Since this approach selects the first block with enough space, it's called First-fit.

2. Circular first-fit: A simple improved variation of the first-fit approach. The circular means we will start from the last position reached in the previous search, instead of always starting from the head. This variation can reduce the number of unnecessary searches.

3. Best Fit: best fit was designed to solve a potential disadvantage of the first-fit approach: it may waste the memory block by breaking a big block into smaller ones. To avoid this waste, the best-fit will search the whole list and find the smallest block that satisfies the requirement. However, this search takes time too. Also, there is another problem that the remaining portion of the best-fit block can be so small that it is useless for future requests.

4. Worst-fit: In contrary to best-fit, the worst-fit approach always takes the largest block. Similar to best-fit, the worst fit also needs to traverse the whole list, or we can order the list by size to reduce cost.

Note: If the sizes of requests vary a lot, the best-fit can be most suitable. However, when the requests are almost equally weighted, the first or worst fit may perform better.

Note: There are other methods for memory allocation:[openDSA](https://canvas.vt.edu/courses/111334/modules/items/901514)

### Failure Policies and Garbage Collection
Sometimes, we will meet a situation that the memory manager doesn't have enough space to satisfy the requirement while the program requires immediate feedback. So the manager has to return a failure message which may lead to a program error. Some failure policies include delay the memory request until there is one block satisfy the requirement, or simply allocate more memory for the memory manager. However, when all these are failed, we need to consider the last failure policy called garbage collection. 

Definition: When memory is unpointed, the memory block is called garbage since we can't access it. Java has a dynamic garbage collector which really helped programmers though with a cost of increased compiling time. On the contrary, C language needs a programmer to manually deallocate the memory to prevent from getting errors. For a detailed introduction of the garbage collection algorithm, check[openDSA](https://canvas.vt.edu/courses/111334/modules/items/901516)


> Indexing

### Definition and background
When handling a large data set, the hashing algorithm that we familiar may not be that useful since we don't always do searches that follow a form like"key to value". Instead, we may encounter some more generalized search which requires a better handling algorithm. In this chapter, we will be focusing on the indexing, a strategy used on disk for a large collection of records.
There are several keywords:
1. Primary key: A unique identifier that each record has.
2. Key field: the data of one record that the search method may according to.

### Approaches
1. Linear Indexing:[openDSA](https://canvas.vt.edu/courses/111334/assignments/883583?module_item_id=901518)

2. ISAM was designed to solve the problem of linear indexing: it doesn't adjust well to the update because a single update may require to change every index of the linear list. This problem is solved by Cylinders. [openDSA](https://canvas.vt.edu/courses/111334/modules/items/901519)

3. Tree-structure: The problem with tree-structure is whether the tree is balanced or not. To solve this, we have an alternative, the 2-3 tree whose leaves are always at the same level.

4. A 2-3 tree follows:1.A node contains one or two keys. 2. Every internal node has either two children (if it contains one key) or three children (if it contains two keys). Hence the name. 3. All leaves are at the same level in the tree, so the tree is always height-balanced.
Some methods from [openDSA](https://canvas.vt.edu/courses/111334/modules/items/901522):
```
// 2-3 tree node implementation
class TTNode<Key extends Comparable<? super Key>,E> {
  private E lval;        // The left record
  private Key lkey;        // The node's left key
  private E rval;        // The right record
  private Key rkey;        // The node's right key
  private TTNode<Key,E> left;   // Pointer to left child
  private TTNode<Key,E> center; // Pointer to middle child
  private TTNode<Key,E> right;  // Pointer to right child

  public TTNode() { center = left = right = null; }
  public TTNode(Key lk, E lv, Key rk, E rv,
                TTNode<Key,E> p1, TTNode<Key,E> p2,
                TTNode<Key,E> p3) {
    lkey = lk; rkey = rk;
    lval = lv; rval = rv;
    left = p1; center = p2; right = p3;
  }

  public boolean isLeaf() { return left == null; }
  public TTNode<Key,E> lchild() { return left; }
  public TTNode<Key,E> rchild() { return right; }
  public TTNode<Key,E> cchild() { return center; }
  public Key lkey() { return lkey; }  // Left key
  public E lval() { return lval; }  // Left value
  public Key rkey() { return rkey; }  // Right key
  public E rval() { return rval; }  // Right value
  public void setLeft(Key k, E e) { lkey = k; lval = e; }
  public void setRight(Key k, E e) { rkey = k; rval = e; }
  public void setLeftChild(TTNode<Key,E> it) { left = it; }
  public void setCenterChild(TTNode<Key,E> it)
    { center = it; }
  public void setRightChild(TTNode<Key,E> it)
    { right = it; }
}
```

Find:
```
private E findhelp(TTNode<Key,E> root, Key k) {
  if (root == null) return null;          // val not found
  if (k.compareTo(root.lkey()) == 0) return root.lval();
  if ((root.rkey() != null) && (k.compareTo(root.rkey())
       == 0))
    return root.rval();
  if (k.compareTo(root.lkey()) < 0)       // Search left
    return findhelp(root.lchild(), k);
  else if (root.rkey() == null)           // Search center
    return findhelp(root.cchild(), k);
  else if (k.compareTo(root.rkey()) < 0)  // Search center
    return findhelp(root.cchild(), k);
  else return findhelp(root.rchild(), k); // Search right
}
```

Insert:
```
private TTNode<Key,E> inserthelp(TTNode<Key,E> rt, Key k, E e) {
  TTNode<Key,E> retval;
  if (rt == null) // Empty tree: create a leaf node for root
    return new TTNode<Key,E>(k, e, null, null, null, null, null);
  if (rt.isLeaf()) // At leaf node: insert here
    return rt.add(new TTNode<Key,E>(k, e, null, null, null, null, null));
  // Add to internal node
  if (k.compareTo(rt.lkey()) < 0) { // Insert left
    retval = inserthelp(rt.lchild(), k, e);
    if (retval == rt.lchild()) return rt;
    else return rt.add(retval);
  }
  else if((rt.rkey() == null) || (k.compareTo(rt.rkey()) < 0)) {
    retval = inserthelp(rt.cchild(), k, e);
    if (retval == rt.cchild()) return rt;
    else return rt.add(retval);
  }
  else { // Insert right
    retval = inserthelp(rt.rchild(), k, e);
    if (retval == rt.rchild()) return rt;
    else return rt.add(retval);
  }
}

// Add a new key/value pair to the node. There might be a subtree
// associated with the record being added. This information comes
// in the form of a 2-3 tree node with one key and a (possibly null)
// subtree through the center pointer field.
public TTNode<Key,E> add(TTNode<Key,E> it) {
  if (rkey == null) { // Only one key, add here
    if (lkey.compareTo(it.lkey()) < 0) {
      rkey = it.lkey(); rval = it.lval();
      center = it.lchild(); right = it.cchild();
    }
    else {
      rkey = lkey; rval = lval; right = center;
      lkey = it.lkey(); lval = it.lval();
      center = it.cchild();
    }
    return this;
  }
  else if (lkey.compareTo(it.lkey()) >= 0) { // Add left
    TTNode<Key,E> N1 = new TTNode<Key,E>(lkey, lval, null, null, it, this, null);
    it.setLeftChild(left);
    left = center; center = right; right = null;
    lkey = rkey; lval = rval; rkey = null; rval = null;
    return N1;
  }
  else if (rkey.compareTo(it.lkey()) >= 0) { // Add center
    it.setCenterChild(new TTNode<Key,E>(rkey, rval, null, null, it.cchild(), right, null));
    it.setLeftChild(this);
    rkey = null; rval = null; right = null;
    return it;
  }
  else { // Add right
    TTNode<Key,E> N1 = new TTNode<Key,E>(rkey, rval, null, null, this, it, null);
    it.setLeftChild(right);
    right = null; rkey = null; rval = null;
    return N1;
  }
}
```

5. B-tree[openDSA](https://canvas.vt.edu/courses/111334/assignments/883585?module_item_id=901524)
In the B-tree, internal (non-leaf) nodes can have a variable number of child nodes (the number range is predefined). When data is inserted or removed from a node, its number of child nodes changes. In order to maintain within a preset number range, internal nodes may be merged or separated. Because the number of child nodes has a certain allowable range, the B-tree does not need to be re-balanced as frequently as other self-balancing search trees, but because the nodes are not completely filled, some space may be wasted. The upper and lower bounds of the number of child nodes are set according to the specific implementation. For example, in a 2-3 B tree (usually referred to as the 2-3 tree), each internal node can only have 2 or 3 child nodes.

Each internal node in the B-tree will contain a certain number of keys, which separate the sub-trees of the nodes. For example, if an internal node has 3 child nodes (subtrees), then it must have two keys: a1 and a2. All values ​​of the left subtree must be less than a1, all values ​​of the middle subtree must be between a1 and a2, and all values ​​of the right subtree must be greater than a2.

Analysis: The cost for insert, search and deletion are O(logn)